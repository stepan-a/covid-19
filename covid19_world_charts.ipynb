{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 World Charts\n",
    "Guillaume Rozier, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nLICENSE MIT\\n2020\\nGuillaume Rozier\\nWebsite : http://www.guillaumerozier.fr\\nMail : guillaume.rozier@telecomnancy.net\\n\\nThis file contains scripts that download data from CSSE (John Hopkins) Github Repository and then process it to build many graphes.\\nI'm currently cleaning the code, please come back soon it will be easier to read and edit it!\\n\\nThe charts are exported to 'charts/images/'.\\nData is download to/imported from 'data/'.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "LICENSE MIT\n",
    "2020\n",
    "Guillaume Rozier\n",
    "Website : http://www.guillaumerozier.fr\n",
    "Mail : guillaume.rozier@telecomnancy.net\n",
    "\n",
    "This file contains scripts that download data from CSSE (John Hopkins) Github Repository and then process it to build many graphes.\n",
    "I'm currently cleaning the code, please come back soon it will be easier to read and edit it!\n",
    "\n",
    "The charts are exported to 'charts/images/'.\n",
    "Data is download to/imported from 'data/'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'build : 2020-04-16 12:28'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import chart_studio\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "\n",
    "colors = px.colors.qualitative.D3 + plotly.colors.DEFAULT_PLOTLY_COLORS + px.colors.qualitative.Plotly + px.colors.qualitative.Dark24 + px.colors.qualitative.Alphabet\n",
    "\n",
    "#If you want to uplaod charts to your Plotly account (and switch \"upload\" to True just below):\n",
    "#chart_studio.tools.set_credentials_file(username='', api_key='')\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\"build : \" + today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to display charts here, please change \"show\" variable to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = False\n",
    "show = False\n",
    "export = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'build : 2020-04-16 12:28'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "if len(sys.argv) >= 2:\n",
    "    if (sys.argv[1]).lower() == \"true\":\n",
    "        upload = True\n",
    "    \n",
    "if len(sys.argv) >= 3:\n",
    "    if (sys.argv[2]).lower() == \"true\":\n",
    "        show = True\n",
    "\n",
    "if len(sys.argv) >= 4:\n",
    "    if (sys.argv[3]).lower() == \"true\":\n",
    "        export = True\n",
    "    \n",
    "\"build : \" + today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_offset(df, col_of_reference, col_to_align, countries):\n",
    "        \n",
    "    diffs = []\n",
    "    for offset in range(len(df)-15):\n",
    "        \n",
    "        a = df[col_of_reference][1:].shift(offset, fill_value=0)/countries[col_of_reference][\"pop\"]\n",
    "        b = df[col_to_align][1:]/countries[col_to_align][\"pop\"]\n",
    "        \n",
    "        if len(a) > len(b):\n",
    "            a = a[:-2]\n",
    "        m = min(len(a), len(b))\n",
    "            \n",
    "        delta = ((a[offset:] - b[offset:])**2)**(1/2)\n",
    "        diffs.append(abs(delta.sum()))\n",
    "        xa = [i for i in range(offset, len(a))]\n",
    "        xb = [i for i in range(offset, len(b))]\n",
    "\n",
    "    ret = diffs.index(min(diffs))\n",
    "\n",
    "    if col_of_reference == col_to_align:\n",
    "        return 0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    #url_confirmed = \"https://cowid.netlify.com/data/total_cases.csv\"\n",
    "    #url_deaths = \"https://cowid.netlify.com/data/total_deaths.csv\"\n",
    "    url_confirmed_csse = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"    \n",
    "    url_deaths_csse = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"    \n",
    "\n",
    "\n",
    "    #r_confirmed = requests.get(url_confirmed)\n",
    "    #r_deaths = requests.get(url_deaths)\n",
    "    r_confirmed_csse = requests.get(url_confirmed_csse)\n",
    "    r_deaths_csse = requests.get(url_deaths_csse)\n",
    "\n",
    "    #with open('data/total_cases_who.csv', 'wb') as f:\n",
    "        #f.write(r_confirmed.content)\n",
    "\n",
    "    #with open('data/total_deaths_who.csv', 'wb') as f:\n",
    "        #f.write(r_deaths.content)\n",
    "\n",
    "    with open('data/total_cases_csse.csv', 'wb') as f:\n",
    "            f.write(r_confirmed_csse.content)\n",
    "\n",
    "    with open('data/total_deaths_csse.csv', 'wb') as f:\n",
    "        f.write(r_deaths_csse.content)\n",
    "\n",
    "    print(\"> data downloaded\")\n",
    "    #\"build : \" + today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_files(): \n",
    "    # CSSE data\n",
    "    df_confirmed_csse = pd.read_csv('data/total_cases_csse.csv')\n",
    "    df_deaths_csse = pd.read_csv('data/total_deaths_csse.csv')\n",
    "\n",
    "    # WHO data\n",
    "    #df_confirmed_who = pd.read_csv('data/total_cases_who.csv')\n",
    "    #df_deaths_who = pd.read_csv('data/total_deaths_who.csv')\n",
    "\n",
    "    # Perso data\n",
    "    df_confirmed_perso = pd.read_csv('data/total_cases_perso.csv')\n",
    "    df_deaths_perso = pd.read_csv('data/total_deaths_perso.csv')\n",
    "\n",
    "    print(\"> data imported\")\n",
    "    return df_confirmed_csse, df_deaths_csse, df_confirmed_perso, df_deaths_perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_csse(df0):\n",
    "    df = df0.drop('Lat', axis=1)\n",
    "    df = df.drop('Long', axis=1)\n",
    "    df = df.drop('Province/State', axis=1)\n",
    "    #df_csse_new2 = df_csse_new.groupby(['Country/Region'])\n",
    "    df = df.T.reset_index()\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.rename(columns={\"Country/Region\": \"date\"})\n",
    "    df = df.drop(df.index[0])\n",
    "    dates = df['date'].values\n",
    "    df = df.groupby(by=df.columns, axis=1).sum(numeric_only=True)\n",
    "    df['date'] = dates\n",
    "    return df\n",
    "\n",
    "#\"build : \" + today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merge(data_confirmed, df_confirmed_perso, data_deaths, df_deaths_perso):\n",
    "    data_confirmed = pd.merge(data_confirmed, df_confirmed_perso, how='outer').drop_duplicates(subset='date')\n",
    "    data_deaths = pd.merge(data_deaths, df_deaths_perso, how='outer').drop_duplicates(subset='date')\n",
    "\n",
    "    #date_int = [i for i in range(len(data_confirmed))]\n",
    "    #data_confirmed[\"date_int\"] = date_int\n",
    "\n",
    "    #date_int = [i for i in range(len(data_deaths))]\n",
    "    #data_deaths[\"date_int\"] = date_int\n",
    "\n",
    "    \"build : \" + today\n",
    "    #data_confirmed['date']\n",
    "    #df_deaths_perso.iloc[-1]\n",
    "    \n",
    "    #for c in countries:\n",
    "     #    data_deaths[c+\"_new\"] = data_deaths[c].diff()\n",
    "    return data_confirmed, data_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rolling(df):\n",
    "    df_r = df\n",
    "    df_r[:len(df_r)-1].fillna(method='pad',inplace=True)\n",
    "    df_r = df.rolling(5, win_type='gaussian', center=True).mean(std=2)\n",
    "    df_r['date'] = df['date'].values\n",
    "    df_r.iloc[len(df_r)-2] = df.iloc[-2]\n",
    "    df_r.iloc[len(df_r)-1] = df.iloc[-1]\n",
    "\n",
    "    #moins_2 = ((df.iloc[-3][:-1] + df.iloc[-1][:-1]) / 2).append(pd.Series([df.iloc[-2][\"date\"]]))\n",
    "    #moins_1 = ((df.iloc[-3][:-1] + df.iloc[-1][:-1]) / 2).append(pd.Series([df.iloc[-1][\"date\"]]))\n",
    "\n",
    "    #df_r.iloc[-2] = moins_2\n",
    "    #df_r.iloc[-1] = moins_1\n",
    "    #data_confirmed.loc[:, data_confirmed.columns != \"date\"]\n",
    "    #df_r = df_r.drop(len(df_r)-1)\n",
    "    #df_r = df_r.drop(len(df_r)-1)\n",
    "    \n",
    "    df_r.loc[len(df_r)-3, df_r.columns != \"date\" ] = ((df.iloc[-4][:-1] + df.iloc[-2][:-1])/2 + df.iloc[-3][:-1])/2\n",
    "    df_r.loc[len(df_r)-3, \"date\"] = df.iloc[-3][\"date\"]\n",
    "    \n",
    "   # df_r.loc[len(df_r)-2, df_r.columns != \"date\" ] = ((df.iloc[-3][:-1] + df.iloc[-1][:-1])/2 + df.iloc[-2][:-1])/2\n",
    "    #df_r.loc[len(df_r)-2, \"date\"] = df.iloc[-2][\"date\"]\n",
    "    \n",
    "    df_r.loc[len(df_r)-2, df_r.columns != \"date\" ] = (df.iloc[-3][:-1] + (df.iloc[-3][:-1] - df.iloc[-4][:-1]) / 2 + df.iloc[-2][:-1])/2\n",
    "    df_r.loc[len(df_r)-2, \"date\"] = df.iloc[-2][\"date\"] \n",
    "    \n",
    "    df_r.loc[len(df_r)-1, df_r.columns != \"date\" ] = (df.iloc[-2][:-1] + (df.iloc[-1][:-1] - df.iloc[-3][:-1]) / 2 + df.iloc[-1][:-1])/2\n",
    "    df_r.loc[len(df_r)-1, \"date\"] = df.iloc[-1][\"date\"] \n",
    "    \n",
    "    return df_r\n",
    "\n",
    "\n",
    "def final_data_prep(data_confirmed, data_confirmed_rolling, data_deaths, data_deaths_rolling):\n",
    "    # Date conversion\n",
    "    data_confirmed['date'] = data_confirmed['date'].astype('datetime64[ns]') \n",
    "    data_confirmed_rolling['date'] = data_confirmed_rolling['date'].astype('datetime64[ns]') \n",
    "\n",
    "    data_deaths['date'] = data_deaths['date'].astype('datetime64[ns]') \n",
    "    data_deaths_rolling['date'] = data_deaths_rolling['date'].astype('datetime64[ns]') \n",
    "\n",
    "    date_int = [i for i in range(len(data_confirmed))]\n",
    "    data_confirmed[\"date_int\"] = date_int\n",
    "\n",
    "    date_int = [i for i in range(len(data_deaths))]\n",
    "    data_deaths[\"date_int\"] = date_int\n",
    "    \n",
    "    #for c in countries:\n",
    "     #    data_deaths[c+\"_new\"] = data_deaths[c].diff()\n",
    "        #data_deaths.loc[vals.index, c+\"_new\"] = vals\n",
    "    return data_confirmed, data_confirmed_rolling, data_deaths, data_deaths_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_confirmed_rolling.tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informations on countries (population, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def offset_compute_export(data_confirmed, data_deaths):\n",
    "    # Importing informations on countries\n",
    "\n",
    "    with open('data/info_countries.json', 'r') as f:\n",
    "        countries = json.load(f)\n",
    "\n",
    "    # Computing offset\n",
    "    i = 0\n",
    "    for c in tqdm(countries):\n",
    "        countries[c]['offset_confirmed'] = compute_offset(data_confirmed, 'Italy', c, countries)\n",
    "        countries[c]['offset_deaths'] = compute_offset(data_deaths, 'Italy', c, countries)\n",
    "        countries[c]['color'] = i\n",
    "        i += 1\n",
    "    # Exporting informations on countries\n",
    "    with open('data/info_countries.json', 'w') as fp:\n",
    "        json.dump(countries, fp)\n",
    "\n",
    "    print(\"> pop data imported\")\n",
    "    \"build : \" + today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df_exports(data_confirmed, data_deaths):\n",
    "    data_confirmed.to_csv('data/data_confirmed.csv')\n",
    "    data_deaths.to_csv('data/data_deaths.csv')\n",
    "    print(\"> dfs exported\")\n",
    "    \n",
    "def data_import():\n",
    "    with open('data/info_countries.json', 'r') as f:\n",
    "        countries = json.load(f)\n",
    "    return pd.read_csv('data/data_confirmed.csv'), pd.read_csv('data/data_deaths.csv'), countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data():\n",
    "    # Data update:\n",
    "    download_data()\n",
    "    df_confirmed_csse, df_deaths_csse, df_confirmed_perso, df_deaths_perso = import_files()\n",
    "\n",
    "    df_confirmed_csse = data_prep_csse(df_confirmed_csse)\n",
    "    df_deaths_csse = data_prep_csse(df_deaths_csse)\n",
    "\n",
    "    data_confirmed, data_deaths = data_merge(df_confirmed_csse, df_confirmed_perso, df_deaths_csse, df_deaths_perso)\n",
    "\n",
    "    data_confirmed_rolling = rolling(data_confirmed)\n",
    "    data_deaths_rolling = rolling(data_deaths)\n",
    "\n",
    "    data_confirmed, data_confirmed_rolling, data_deaths, data_deaths_rolling = final_data_prep(data_confirmed, data_confirmed_rolling, data_deaths, data_deaths_rolling)\n",
    "\n",
    "    offset_compute_export(data_confirmed, data_deaths)\n",
    "\n",
    "    final_df_exports(data_confirmed, data_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "This fonction builds and export graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart(data, data_rolling, countries, by_million_inh = False, align_curves = False, last_d = 15, offset_name = 'offset_confirmed', type_ppl = \"confirmed cases\", name_fig=\"\", since=False, min_rate=0, log=False, new=\"\"):\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    ### Symbols\n",
    "    symbols = []\n",
    "    for i in range(35):\n",
    "        symbols.append(SymbolValidator().values[i])\n",
    "    random.shuffle(symbols)\n",
    "    ###\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    x_an=np.array([])\n",
    "    y_an=np.array([])\n",
    "    \n",
    "    countries_last_val = []\n",
    "    countries_array = []\n",
    "    for c in countries:\n",
    "        if by_million_inh:\n",
    "             val = data[c][len(data) - 1]/countries[c]['pop']\n",
    "        else:\n",
    "            val = data[c][len(data) - 1]\n",
    "            \n",
    "        countries_last_val.append(val)\n",
    "        countries_array.append(c)\n",
    "        \n",
    "    ind = np.argsort(countries_last_val)\n",
    "    countries_array = np.array(countries_array)\n",
    "    countries_array = countries_array[ind][::-1]\n",
    "        \n",
    "    for c in countries_array:\n",
    "\n",
    "        if align_curves:\n",
    "            offset = countries[c][offset_name]\n",
    "            offset2 = -offset\n",
    "        else:\n",
    "            offset = 0\n",
    "\n",
    "        if offset==0: offset2 = None\n",
    "\n",
    "        if by_million_inh:\n",
    "            pop = countries[c]['pop']\n",
    "        else:\n",
    "            pop = 1\n",
    "        \n",
    "        date = 'date'\n",
    "        offset3=0\n",
    "        since_str = \"\"\n",
    "        since_str_leg = \"\"\n",
    "        \n",
    "        if since:\n",
    "            date = 'date_int'\n",
    "            res = list(map(lambda i: i> min_rate, data[c+new].values / pop))\n",
    "            offset2 = 0\n",
    "            if True in res:\n",
    "                ind = res.index(True) \n",
    "                offset2 = -ind\n",
    "                since_str_leg = \" [since {} days]\".format(len(data) - ind)\n",
    "\n",
    "            offset3 = offset2\n",
    "            last_d = 0\n",
    "            offset = 0\n",
    "            since_str = \" [since {}]\".format(min_rate) #, type_ppl\n",
    "            \n",
    "            if by_million_inh:\n",
    "                since_str = since_str[:-1] + \"/1M inh.]\"\n",
    "                \n",
    "\n",
    "        x = data[date][ -last_d - offset: offset2]\n",
    "        y = data[c+new][-last_d - offset3:] / pop\n",
    "        \n",
    "        if offset != 0:\n",
    "            name_legend = '{} [delayed by {} days]'.format(c, -offset)\n",
    "        else:\n",
    "            name_legend = '{} {}'.format(c, since_str_leg)\n",
    "        txt=[\"\" for i in range(len(data_rolling[c][-last_d - offset3:]))]\n",
    "        txt[-1] = c\n",
    "        fig.add_trace(go.Scatter(x = x, y = y,\n",
    "                        mode='markers',\n",
    "                        marker_color = colors[countries[c]['color']],\n",
    "                        legendgroup = c,\n",
    "                        marker_symbol = countries[c]['color'],\n",
    "                        marker_size=9,\n",
    "                        #marker_line_width=2,\n",
    "                        opacity=1,\n",
    "                        showlegend=True,\n",
    "                        name = name_legend))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x = data_rolling[date][ -last_d - offset : offset2], y = data_rolling[c+new][-last_d - offset3:] / pop,\n",
    "                        mode='lines',\n",
    "                        marker_color = colors[countries[c]['color']],\n",
    "                        opacity = 1,\n",
    "                        legendgroup=c,\n",
    "                        showlegend=False,\n",
    "                        line=dict(width=2),\n",
    "                        name = name_legend))\n",
    "        i += 1\n",
    "        j += 1\n",
    "        \n",
    "        if i >= len(colors):\n",
    "            i = 0\n",
    "            \n",
    "        if j >= 40:\n",
    "            j = 0\n",
    "        \n",
    "        if log and since and c==\"Italy\":\n",
    "            date_start = data_rolling['date_int'].values[ -last_d - offset]\n",
    "            \n",
    "            x = data_rolling[\"date_int\"][ -last_d - offset : offset2]\n",
    "            \n",
    "            max_values = 15\n",
    "            for (rate, rate_str) in [(2**(1/10), \"x2 every 10 days\"), (2**(1/7), \"x2 every 7 days\"), (2**(1/3), \"x2 every 3 days\"), (2**(1/2), \"x2 every 2 days\"), (2**(1/5), \"x2 every 5 days\")]:\n",
    "                \n",
    "                y = rate ** (data_rolling[\"date_int\"][ -last_d - offset : offset2].values - date_start) * min_rate\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x = x[:max_values+1], y = y[:max_values+1],\n",
    "                                mode='lines+text',\n",
    "                                marker_color=\"grey\",\n",
    "                                opacity=1,\n",
    "                                #text = rate_str,\n",
    "                                textposition = \"bottom right\",\n",
    "                                legendgroup=\"Tendance\",\n",
    "                                showlegend=False,\n",
    "                                line=dict(\n",
    "                                    width=1,\n",
    "                                    dash='dot'\n",
    "                                ),\n",
    "                                name = \"Tendance\"))\n",
    "\n",
    "                fig.add_trace(go.Scatter(x = [data_rolling[\"date_int\"][ -last_d - offset : offset2].values[max_values]], y = [(rate ** (data_rolling[\"date_int\"][ -last_d - offset : offset2].values - date_start) * min_rate)[max_values]],\n",
    "                                mode='text',\n",
    "                                marker_color=\"grey\",\n",
    "                                opacity=1,\n",
    "                                text = rate_str,\n",
    "                                textposition = \"bottom right\",\n",
    "                                legendgroup=\"Tendance\",\n",
    "                                showlegend=False,\n",
    "                                name = \"Tendance\"))\n",
    "            \n",
    "    ### END LOOP ###\n",
    "    \n",
    "    align_str = \"\"\n",
    "    if align_curves:\n",
    "        align_str = \" [aligned]\"\n",
    "        \n",
    "    million_str = \"\"\n",
    "    million_str_ax = \"\"\n",
    "    if by_million_inh:\n",
    "        million_str = \" for 1M inhabitants\"\n",
    "        million_str_ax = \"/ nb of inhabitants (million)\"\n",
    "        \n",
    "    delayed=\"\"\n",
    "    if align_curves:\n",
    "        delayed=\"— delayed for some countries\"\n",
    "    if since:\n",
    "        delayed =\"— since {} {} {}\".format(min_rate, type_ppl, million_str)\n",
    "    \n",
    "    fig.update_annotations(dict(\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            showarrow=True,\n",
    "            arrowhead=7\n",
    "    ))\n",
    "    log_str=\"linear\"\n",
    "    \n",
    "    if log:\n",
    "        log_str = \"log\"\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=True,\n",
    "        title={\n",
    "            'text': \"COVID-19 <b>{}{}</b>{}{}\".format(type_ppl, million_str, align_str, since_str),\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "        xaxis_title=\"Day {} {}\".format(delayed, ''),\n",
    "        yaxis_type=log_str,\n",
    "        yaxis_title=\"Total {} {}\".format(type_ppl, million_str),\n",
    "        titlefont = dict(\n",
    "            size=28),\n",
    "        annotations = [dict(xref='paper',\n",
    "            yref='paper',\n",
    "            x=0, y=1.05,\n",
    "            showarrow=False,\n",
    "            text ='Last update: {} ; Last data: {} ; Data: CSSE ; Author: @guillaumerozier'.format(today, str(data['date'].values[-1])[:10]))]\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(nticks = last_d)\n",
    "\n",
    "    print(\"> graph built\")\n",
    "\n",
    "    if upload:\n",
    "        py.plot(fig, filename = name_fig, auto_open=False)\n",
    "        print(\"> graph uploaded\")\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "        print(\"> graph showed\")\n",
    "\n",
    "    if export:\n",
    "        path_log = \"\"\n",
    "        if log:\n",
    "            path_log = \"log_yaxis/\"\n",
    "        fig.write_image(\"images/charts/{}{}.png\".format(path_log, name_fig), scale=3, width=1100, height=700)\n",
    "        fig.write_image(\"images/charts_sd/{}{}.png\".format(path_log, name_fig), scale=0.5)\n",
    "        plotly.offline.plot(fig, filename = 'images/html_exports/{}{}.html'.format(path_log, name_fig), auto_open=False)\n",
    "        print(\"> graph exported\\n\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calls\n",
    "This block contains calls to above function for every chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> data downloaded\n",
      "> data imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4259: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4259: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pop data imported\n",
      "> dfs exported\n",
      "cases\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant_aligned\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant_aligned\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant_aligned\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_per_1m_inhabitant_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "cases_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant_aligned\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_per_1m_inhabitant_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n",
      "deaths_since\n",
      "> graph built\n",
      "> graph exported\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_data()\n",
    "data_confirmed, data_deaths, countries = data_import()\n",
    "\n",
    "for log in False, True:\n",
    "    # Confirmed cases\n",
    "    name = \"cases\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_confirmed, \n",
    "          data_rolling = data_confirmed, \n",
    "          by_million_inh = False, \n",
    "          last_d = round(len(data_confirmed)/2),\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    name = \"cases_per_1m_inhabitant\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_confirmed, \n",
    "          data_rolling = data_confirmed, \n",
    "          by_million_inh = True, \n",
    "          last_d = round(len(data_confirmed)/2),\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    name = \"cases_per_1m_inhabitant_aligned\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_confirmed, \n",
    "          data_rolling = data_confirmed, \n",
    "          by_million_inh = True, \n",
    "          last_d = 40, \n",
    "          align_curves = True,\n",
    "          offset_name = 'offset_confirmed',\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    name = \"cases_per_1m_inhabitant_since\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_confirmed, \n",
    "          data_rolling = data_confirmed, \n",
    "          by_million_inh = True, \n",
    "          align_curves = False,\n",
    "          since=True,\n",
    "          name_fig = name,\n",
    "          min_rate=20,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    \n",
    "    name = \"cases_since\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_confirmed, \n",
    "          data_rolling = data_confirmed, \n",
    "          by_million_inh = False, \n",
    "          align_curves = False,\n",
    "          since=True,\n",
    "          name_fig = name,\n",
    "          min_rate=1000,\n",
    "          log=log\n",
    "         )\n",
    "    \n",
    "\n",
    "    # Deaths\n",
    "    name = \"deaths\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_deaths, \n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = False, \n",
    "          last_d = round(len(data_deaths)/2),\n",
    "          type_ppl = \"deaths\",\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "    \n",
    "    \"\"\"name = \"deaths_new_since\"\n",
    "    print(name)\n",
    "    chart(countries = countries,\n",
    "          new = \"_new\",\n",
    "          data = data_deaths,\n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = False, \n",
    "          last_d = round(len(data_deaths)/2),\n",
    "          type_ppl = \"deaths\",\n",
    "          name_fig = name,\n",
    "          since=True,\n",
    "          min_rate=10,\n",
    "          log=log\n",
    "         )\"\"\"\n",
    "\n",
    "    name = \"deaths_per_1m_inhabitant\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_deaths, \n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = True, \n",
    "          last_d = round(len(data_deaths)/2),\n",
    "          type_ppl = \"deaths\",\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    name = \"deaths_per_1m_inhabitant_aligned\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_deaths, \n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = True, \n",
    "          last_d = 35, \n",
    "          align_curves = True,\n",
    "          offset_name = 'offset_deaths',\n",
    "          type_ppl = \"deaths\",\n",
    "          name_fig = name,\n",
    "          log=log\n",
    "         )\n",
    "\n",
    "    name = \"deaths_per_1m_inhabitant_since\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_deaths, \n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = True, \n",
    "          align_curves = False,\n",
    "          type_ppl = \"deaths\",\n",
    "          since=True,\n",
    "          name_fig = name,\n",
    "          min_rate=3,\n",
    "          log=log\n",
    "         )\n",
    "    \n",
    "    name = \"deaths_since\"\n",
    "    print(name)\n",
    "    chart(countries=countries,\n",
    "          data = data_deaths, \n",
    "          data_rolling = data_deaths, \n",
    "          by_million_inh = False, \n",
    "          last_d = 20, \n",
    "          align_curves = False,\n",
    "          type_ppl = \"deaths\",\n",
    "          since=True,\n",
    "          name_fig = name,\n",
    "          min_rate=100,\n",
    "          log=log\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTATIONS (SEIR model)\n",
    "Currently not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "t_max = 100\n",
    "dt = .1\n",
    "t = np.linspace(0, t_max, int(t_max/dt) + 1)\n",
    "N = 10000\n",
    "init_vals = 1 - 1/N, 1/N, 0, 0\n",
    "alpha = 0.2\n",
    "beta = 1.75\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "params = alpha, beta, gamma, rho\n",
    "# Run simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seir_model_with_soc_dist(init_vals, params, t):\n",
    "    S_0, E_0, I_0, R_0 = init_vals\n",
    "    S, E, I, R = [S_0], [E_0], [I_0], [R_0]\n",
    "    alpha, beta, gamma, rho = params\n",
    "    dt = t[1] - t[0]\n",
    "    for _ in t[1:]:\n",
    "        next_S = S[-1] - (rho*beta*S[-1]*I[-1])*dt\n",
    "        next_E = E[-1] + (rho*beta*S[-1]*I[-1] - alpha*E[-1])*dt\n",
    "        next_I = I[-1] + (alpha*E[-1] - gamma*I[-1])*dt\n",
    "        next_R = R[-1] + (gamma*I[-1])*dt\n",
    "        S.append(next_S)\n",
    "        E.append(next_E)\n",
    "        I.append(next_I)\n",
    "        R.append(next_R)\n",
    "    return np.stack([S, E, I, R]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seir_model_with_soc_dist(init_vals, params, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
