{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guillaume Rozier - 2020 - MIT License\n",
    "# This script will automatically tweet new data and graphes on the account @covidtracker_fr\n",
    "\n",
    "# importing the module \n",
    "\n",
    "import france_data_management as data\n",
    "import math\n",
    "from datetime import datetime\n",
    "import locale\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import secrets as s\n",
    "from datetime import timedelta\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR.UTF-8')\n",
    "\n",
    "\"\"\"\n",
    "Secrets :\n",
    "    consumer_key =\"xxxxxxxxxxxxxxxx\"\n",
    "    consumer_secret =\"xxxxxxxxxxxxxxxx\"\n",
    "    access_token =\"xxxxxxxxxxxxxxxx\"\n",
    "    access_token_secret =\"xxxxxxxxxxxxxxxx\"\n",
    "\"\"\"\n",
    "\n",
    "# authentication \n",
    "auth = tweepy.OAuthHandler(s.consumer_key, s.consumer_secret) \n",
    "auth.set_access_token(s.access_token, s.access_token_secret) \n",
    "\n",
    "api = tweepy.API(auth) \n",
    "    \n",
    "def tweet_france():\n",
    "    #data.download_data()\n",
    "    _, _, dates, df_new, _, _, _, df_incid, _ = data.import_data()\n",
    "    df_new_france = df_new.groupby([\"jour\"]).sum().reset_index()\n",
    "    df_incid_france = df_incid.groupby([\"jour\"]).sum().reset_index()\n",
    "    \n",
    "    lastday_df_new = datetime.strptime(df_new_france['jour'].max(), '%Y-%m-%d')\n",
    "    \n",
    "    hosp = df_new_france[df_new_france['jour']==lastday_df_new.strftime('%Y-%m-%d')]['incid_hosp'].values[-1]\n",
    "    date_j7 = (lastday_df_new - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "    hosp_j7 = df_new_france[df_new_france['jour'] == date_j7]['incid_hosp'].values[-1]\n",
    "    \n",
    "    \n",
    "    deaths = df_new_france[df_new_france['jour']==lastday_df_new.strftime('%Y-%m-%d')]['incid_dc'].values[-1]\n",
    "    deaths_j7 = df_new_france[df_new_france['jour'] == date_j7]['incid_dc'].values[-1]\n",
    "    \n",
    "    lastday_df_incid = datetime.strptime(df_incid_france['jour'].max(), '%Y-%m-%d')\n",
    "    tests = df_incid_france[df_incid_france['jour']==lastday_df_incid.strftime('%Y-%m-%d')]['P'].values[-1]\n",
    "    date_j7_incid = (lastday_df_incid - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "    tests_j7 = df_incid_france[df_incid_france['jour'] == date_j7_incid]['P'].values[-1]\n",
    "    \n",
    "    date = datetime.strptime(dates[-1], '%Y-%m-%d').strftime('%d %B')\n",
    "    \n",
    "    hosp_tendance, hosp_sign = \"en hausse\", \"+\"\n",
    "    if hosp_j7>hosp:\n",
    "        hosp_tendance, hosp_sign = \"en baisse\", \"\"\n",
    "    if hosp_j7==hosp:\n",
    "        hosp_tendance, hosp_sign = \"stable\", \"+\"\n",
    "        \n",
    "    deaths_tendance, deaths_sign = \"en hausse\", \"+\"\n",
    "    if deaths_j7>deaths:\n",
    "        deaths_tendance, deaths_sign = \"en baisse\", \"\"\n",
    "    if deaths_j7==deaths:\n",
    "        deaths_tendance, deaths_sign = \"stable\", \"+\"\n",
    "        \n",
    "    tests_tendance, tests_sign = \"en hausse\", \"+\"\n",
    "    if tests_j7>tests:\n",
    "        tests_tendance, tests_sign = \"en baisse\", \"\"\n",
    "    if tests_j7==tests:\n",
    "        tests_tendance, tests_sign = \"stable\", \"+\"\n",
    "        \n",
    "    date_incid = datetime.strptime(sorted(list(dict.fromkeys(list(df_incid_france['jour'].values))))[-1], '%Y-%m-%d').strftime('%d %B')\n",
    "    tweet =\"Chiffres #Covid19 France :\\n‚Ä¢ {} personnes d√©c√©d√©es en milieu hospitalier ({}), {} sur 7 jours ({}{})\\n‚Ä¢ {} admissions √† l'h√¥pital ({}), {} sur 7 jours ({}{})\\n‚Ä¢ {} cas positifs ({}), {} sur 7 jours ({}{})\\n‚û°Ô∏è Plus d'infos : covidtracker.fr/covidtracker-france\".format(deaths, lastday_df_new.strftime('%d/%m'), deaths_tendance, deaths_sign, deaths-deaths_j7, hosp, lastday_df_new.strftime('%d/%m'), hosp_tendance, hosp_sign, hosp-hosp_j7, tests, lastday_df_incid.strftime('%d/%m'), tests_tendance, tests_sign, tests-tests_j7) # toDo \n",
    "    \n",
    "    images_path =[\"images/charts/france/var_journ_lines_recent.jpeg\", \"images/charts/france/entrees_sorties_hosp_rea_ROLLING_recent.jpeg\", \"images/charts/france/dc_new_bar.jpeg\", \"images/charts/france/reffectif.jpeg\"]\n",
    "    media_ids = []\n",
    "    \n",
    "    for filename in images_path:\n",
    "        res = api.media_upload(filename)\n",
    "        media_ids.append(res.media_id)\n",
    "\n",
    "    # to attach the media file \n",
    "    api.update_status(status=tweet, media_ids=media_ids)\n",
    "    #print(tweet)\n",
    "    \n",
    "    \n",
    "def tweet_france_maps():\n",
    "    _, _, dates, _, _, _, _, df_incid, _ = data.import_data()\n",
    "    lastday_df_incid = datetime.strptime(df_incid['jour'].max(), '%Y-%m-%d')\n",
    "    \n",
    "    ## TWEET2\n",
    "    df_incid_lastday = df_incid.loc[df_incid['jour']==df_incid['jour'].max(), :]\n",
    "    nb_dep = len(df_incid_lastday.loc[df_incid_lastday['incidence_color']=='Rouge (>50)', :])\n",
    "    \n",
    "    images_path2 =[\"images/charts/france/dep-map-incid-cat/latest.jpeg\"]\n",
    "    media_ids2 = []\n",
    "    \n",
    "    for filename in images_path2:\n",
    "        res = api.media_upload(filename)\n",
    "        media_ids2.append(res.media_id)\n",
    "        \n",
    "    tweet2 = \"üî¥ {} d√©partements devraient √™tre class√©s rouge, car ils d√©passent le niveau d'alerte de 50 cas pour 100 000 habitants en 7 jours (donn√©es du {})\\n‚û°Ô∏è Plus d'infos : covidtracker.fr/covidtracker-france\".format(nb_dep, lastday_df_incid.strftime('%d/%m'))\n",
    "    api.update_status(status=tweet2, media_ids=media_ids2)\n",
    "    #print(tweet2)\n",
    "    \n",
    "def tweet_world():\n",
    "    # Import data\n",
    "    df_confirmed_csse = pd.read_csv('data/total_cases_csse.csv')\n",
    "    df_deaths_csse = pd.read_csv('data/total_deaths_csse.csv')\n",
    "    \n",
    "    df_confirmed = pd.read_csv('data/data_confirmed.csv')\n",
    "    df_deaths = pd.read_csv('data/data_deaths.csv')\n",
    "    \n",
    "    # Compute diff to get daily data\n",
    "    df_confirmed_diff = df_confirmed.copy()\n",
    "    df_confirmed_diff.loc[:, df_confirmed.columns != 'date'] = df_confirmed.loc[:, df_confirmed.columns != 'date'] .diff()\n",
    "\n",
    "    df_deaths_diff = df_deaths.copy()\n",
    "    df_deaths_diff.loc[:, df_deaths.columns != 'date'] = df_deaths.loc[:, df_deaths.columns != 'date'] .diff()\n",
    "    \n",
    "    # Get only last day\n",
    "    date = max(df_confirmed[\"date\"])\n",
    "    date_str = datetime.strptime(date, '%Y-%m-%d').strftime('%d %B')\n",
    "\n",
    "    df_confirmed_lastd = df_confirmed[df_confirmed[\"date\"] == date]\n",
    "    df_confirmed_diff_lastd = df_confirmed_diff[df_confirmed_diff[\"date\"] == date]\n",
    "\n",
    "    df_deaths_lastd = df_deaths[df_deaths[\"date\"] == date]\n",
    "    df_deaths_diff_lastd = df_deaths_diff[df_deaths_diff[\"date\"] == date]\n",
    "    \n",
    "    # Get results\n",
    "    sum_cases = math.trunc(df_confirmed_lastd.sum(axis=1).values[0])\n",
    "    new_cases = math.trunc(df_confirmed_diff_lastd.sum(axis=1).values[0])\n",
    "\n",
    "    sum_deaths = math.trunc(df_deaths_lastd.sum(axis=1).values[0])\n",
    "    new_deaths = math.trunc(df_deaths_diff_lastd.sum(axis=1).values[0])\n",
    "    \n",
    "    # Write and publish tweet\n",
    "    tweet =\"Donn√©es du #Covid19 dans le monde au {} :\\n+ {} cas en 24h, soit {} au total\\n+ {} d√©c√®s en 24h, soit {} au total\\n‚û°Ô∏è Plus d'infos : covidtracker.fr/covidtracker-world\\n\".format(date_str, f\"{new_cases:,d}\".replace(',', ' '), f\"{sum_cases:,d}\".replace(',', ' '), f\"{new_deaths:,d}\".replace(',', ' '), f\"{sum_deaths:,d}\".replace(',', ' ')) # toDo \n",
    "    #image_path =\"images/charts/cases_world.jpeg\"\n",
    "    \n",
    "    images_path =[\"images/charts/cases_world.jpeg\", \"images/charts/deaths_world.jpeg\"]\n",
    "    media_ids = []\n",
    "    \n",
    "    for filename in images_path:\n",
    "        res = api.media_upload(filename)\n",
    "        media_ids.append(res.media_id)\n",
    "\n",
    "    # to attach the media file \n",
    "    api.update_status(status=tweet, media_ids=media_ids)\n",
    "    #print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dep date_de_passage sursaud_cl_age_corona  nbre_pass_corona  \\\n",
      "0        01      2020-02-24                     0               0.0   \n",
      "1        01      2020-02-24                     A               0.0   \n",
      "2        01      2020-02-24                     B               0.0   \n",
      "3        01      2020-02-24                     C               0.0   \n",
      "4        01      2020-02-24                     D               0.0   \n",
      "...     ...             ...                   ...               ...   \n",
      "123013  976      2020-09-13                     A               0.0   \n",
      "123014  976      2020-09-13                     B               0.0   \n",
      "123015  976      2020-09-13                     C               0.0   \n",
      "123016  976      2020-09-13                     D               0.0   \n",
      "123017  976      2020-09-13                     E               0.0   \n",
      "\n",
      "        nbre_pass_tot  nbre_hospit_corona  nbre_pass_corona_h  \\\n",
      "0               357.0                 0.0                 0.0   \n",
      "1                73.0                 0.0                 NaN   \n",
      "2               155.0                 0.0                 NaN   \n",
      "3                61.0                 0.0                 NaN   \n",
      "4                28.0                 0.0                 NaN   \n",
      "...               ...                 ...                 ...   \n",
      "123013           34.0                 0.0                 NaN   \n",
      "123014           43.0                 0.0                 NaN   \n",
      "123015            4.0                 0.0                 NaN   \n",
      "123016            1.0                 0.0                 NaN   \n",
      "123017            1.0                 0.0                 NaN   \n",
      "\n",
      "        nbre_pass_corona_f  nbre_pass_tot_h  nbre_pass_tot_f  ...  \\\n",
      "0                      0.0            202.0            155.0  ...   \n",
      "1                      NaN              NaN              NaN  ...   \n",
      "2                      NaN              NaN              NaN  ...   \n",
      "3                      NaN              NaN              NaN  ...   \n",
      "4                      NaN              NaN              NaN  ...   \n",
      "...                    ...              ...              ...  ...   \n",
      "123013                 NaN              NaN              NaN  ...   \n",
      "123014                 NaN              NaN              NaN  ...   \n",
      "123015                 NaN              NaN              NaN  ...   \n",
      "123016                 NaN              NaN              NaN  ...   \n",
      "123017                 NaN              NaN              NaN  ...   \n",
      "\n",
      "        nbre_acte_corona  nbre_acte_tot  nbre_acte_corona_h  \\\n",
      "0                    NaN            NaN                 NaN   \n",
      "1                    NaN            NaN                 NaN   \n",
      "2                    NaN            NaN                 NaN   \n",
      "3                    NaN            NaN                 NaN   \n",
      "4                    NaN            NaN                 NaN   \n",
      "...                  ...            ...                 ...   \n",
      "123013               NaN            NaN                 NaN   \n",
      "123014               NaN            NaN                 NaN   \n",
      "123015               NaN            NaN                 NaN   \n",
      "123016               NaN            NaN                 NaN   \n",
      "123017               NaN            NaN                 NaN   \n",
      "\n",
      "        nbre_acte_corona_f  nbre_acte_tot_h  nbre_acte_tot_f  departmentCode  \\\n",
      "0                      NaN              NaN              NaN              01   \n",
      "1                      NaN              NaN              NaN              01   \n",
      "2                      NaN              NaN              NaN              01   \n",
      "3                      NaN              NaN              NaN              01   \n",
      "4                      NaN              NaN              NaN              01   \n",
      "...                    ...              ...              ...             ...   \n",
      "123013                 NaN              NaN              NaN             976   \n",
      "123014                 NaN              NaN              NaN             976   \n",
      "123015                 NaN              NaN              NaN             976   \n",
      "123016                 NaN              NaN              NaN             976   \n",
      "123017                 NaN              NaN              NaN             976   \n",
      "\n",
      "        departmentName regionCode            regionName  \n",
      "0                  Ain       84.0  Auvergne-Rh√¥ne-Alpes  \n",
      "1                  Ain       84.0  Auvergne-Rh√¥ne-Alpes  \n",
      "2                  Ain       84.0  Auvergne-Rh√¥ne-Alpes  \n",
      "3                  Ain       84.0  Auvergne-Rh√¥ne-Alpes  \n",
      "4                  Ain       84.0  Auvergne-Rh√¥ne-Alpes  \n",
      "...                ...        ...                   ...  \n",
      "123013         Mayotte        6.0               Mayotte  \n",
      "123014         Mayotte        6.0               Mayotte  \n",
      "123015         Mayotte        6.0               Mayotte  \n",
      "123016         Mayotte        6.0               Mayotte  \n",
      "123017         Mayotte        6.0               Mayotte  \n",
      "\n",
      "[123018 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:05,  1.90it/s]                      \u001b[A\n"
     ]
    }
   ],
   "source": [
    "#tweet_world()\n",
    "#tweet_france()\n",
    "#tweet_france_maps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
